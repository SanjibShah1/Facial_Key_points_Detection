{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4100cc1776a19fa",
   "metadata": {},
   "source": [
    "# Facial_key_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4ada123ec75ec",
   "metadata": {},
   "source": [
    "### IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e499596a38ba6c63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T05:52:49.114174Z",
     "start_time": "2024-09-23T05:52:38.661824Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3479928ee20d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:27:17.529042Z",
     "start_time": "2024-09-23T03:27:17.521545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc876550aed3728",
   "metadata": {},
   "source": [
    "### HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c9a849c151aa5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:28:34.797228Z",
     "start_time": "2024-09-23T03:28:34.781749Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model_input_size = 224\n",
    "learning_rate = 0.001\n",
    "n_epoch = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6493a28f73cb0",
   "metadata": {},
   "source": [
    "### DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef20c090cea33c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:27.397117Z",
     "start_time": "2024-09-23T03:50:27.298641Z"
    }
   },
   "outputs": [],
   "source": [
    "class FacialKeyPointsDataset(Dataset):\n",
    "    def __init__(self, csv_file_path = r'data/training_frames_keypoints.csv', split = 'training',device=torch.device('cpu')):  \n",
    "        super().__init__()\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.split = split\n",
    "        self.df = pd.read_csv(self.csv_file_path)\n",
    "        # print(self.df)    -->1\n",
    "        self.normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],   #[r,g,b]\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, original_size = self.get_img(idx)\n",
    "        facial_keypoints = self.get_keypoints(index = idx, original_size = original_size)\n",
    "        return img, facial_keypoints\n",
    "    \n",
    "    \n",
    "    def get_img(self, index):    \n",
    "        img_path = os.path.join(os.path.join(os.getcwd(), 'data', self.split, self.df.iloc[index,0]))\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        original_size = img.size\n",
    "        img = img.resize((model_input_size, model_input_size))\n",
    "        img = np.asarray(img)/255.0 \n",
    "        img = torch.tensor(img,dtype= torch.float32).permute(2,0,1)\n",
    "        img = self.normalize(img)\n",
    "        return img.to(self.device), original_size\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_keypoints(self, index,original_size):\n",
    "        kp = self.df.iloc[index, 1:].to_numpy().astype(np.float32) \n",
    "        kp_x = kp[0::2] / original_size[0]\n",
    "        kp_y = kp[1::2] / original_size[1]\n",
    "        kp = np.concatenate([kp_x, kp_y]).astype(np.float32) \n",
    "        return torch.tensor(kp).to(self.device)\n",
    "    \n",
    "    \n",
    "    def load_img(self, index): \n",
    "        img_path = os.path.join(os.getcwd(), 'data', self.split, self.df.iloc[index,0])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((model_input_size, model_input_size))\n",
    "        return np.asarray(img) / 255.0\n",
    "        \n",
    "\n",
    "training_data = FacialKeyPointsDataset(device=device)\n",
    "test_data = FacialKeyPointsDataset(csv_file_path=r'data/test_frames_keypoints.csv', split='test', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "12f10ad9e450fc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:32.824971Z",
     "start_time": "2024-09-23T03:50:32.811379Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86950b7c80bfc6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:33.116654Z",
     "start_time": "2024-09-23T03:50:33.029157Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_img, batch_key_points = next(iter(train_dataloader))\n",
    "batch_img.shape, batch_key_points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765c48306cdcbac",
   "metadata": {},
   "source": [
    "### DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da008f03e8cfd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:33.701200Z",
     "start_time": "2024-09-23T03:50:33.418237Z"
    }
   },
   "outputs": [],
   "source": [
    "img_index = 26\n",
    "img = training_data.load_img(img_index)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)   #(nrows, ncols, index)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Image with Facial Keypoints\")\n",
    "plt.imshow(img)\n",
    "\n",
    "img_tensor, kp_s = training_data[img_index]\n",
    "kp_s = kp_s.to('cpu')\n",
    "plt.scatter(kp_s[:68] * model_input_size, kp_s[68:] * model_input_size, c='y',s = 2) # denormalize keypoints (kp_x * 224, kp_y*224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573375f59bfaad1",
   "metadata": {},
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4b13ca4cab1f87ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:34.931780Z",
     "start_time": "2024-09-23T03:50:33.766200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(device): \n",
    "    model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    for layers in model.parameters():\n",
    "        layers.requires_grad = False\n",
    "    model.avgpool = nn.Sequential(\n",
    "        nn.Conv2d(512, 512, 3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Flatten()\n",
    "    )\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(2048, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 136),\n",
    "        nn.Sigmoid() \n",
    "    )\n",
    "    return model.to(device=device)\n",
    "model = get_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "329b57d5459cde07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:34.966314Z",
     "start_time": "2024-09-23T03:50:34.956597Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52980524162f336c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:35.028303Z",
     "start_time": "2024-09-23T03:50:34.970495Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(imgs, kps, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward Pass\n",
    "    kps_pred = model(imgs)\n",
    "    loss = criterion(kps_pred, kps)\n",
    "\n",
    "    # backward Pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d680560fc67cfc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:50:35.392467Z",
     "start_time": "2024-09-23T03:50:35.390171Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation_batch(imgs, kps, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    kps_pred = model(imgs)\n",
    "    loss = criterion(kps_pred, kps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6394af0ccd0ad3c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed8f741ba4e534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T03:56:38.288530Z",
     "start_time": "2024-09-23T03:50:36.461088Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(1, n_epoch+1):\n",
    "    epoch_train_loss, epoch_test_loss = 0, 0 \n",
    "\n",
    "    # train \n",
    "    for images, kps in tqdm(train_dataloader, desc=f'Training {epoch} of {n_epoch}'):\n",
    "        # images, kps = \n",
    "        loss = train_batch(images, kps, model, criterion, optimizer)\n",
    "        epoch_train_loss+= loss.item()\n",
    "    epoch_train_loss /= len(train_dataloader)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "   \n",
    "    # validation\n",
    "    for images, kps in tqdm(test_dataloader, desc=\"validation\"):\n",
    "        loss = validation_batch(images, kps, model, criterion)\n",
    "        epoch_test_loss += loss.item()\n",
    "    epoch_test_loss /= len(test_dataloader)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} of {n_epoch}: Training Loss: {epoch_train_loss}, Test Loss: {epoch_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931c2064b58ca6a",
   "metadata": {},
   "source": [
    "### TRAIN AND TEST CURVE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7794d03a7751657",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, n_epoch+1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, test_loss, 'r', label='Test Loss')\n",
    "plt.title(\"Training and Test Loss Curve Over Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27ae9f16ea1a5f",
   "metadata": {},
   "source": [
    "### INFERENCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a4777fb7d5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 11\n",
    "img = test_data.load_img(img_index)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Image with Facial Keypoints\")\n",
    "plt.imshow(img)\n",
    "\n",
    "img, _ = test_data[img_index]\n",
    "kp_s = model(img[None]).flatten().detach().cpu()\n",
    "kp_s = kp_s.to('cpu')\n",
    "plt.scatter(kp_s[:68] * model_input_size, kp_s[68:] * model_input_size, c='y',s = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
